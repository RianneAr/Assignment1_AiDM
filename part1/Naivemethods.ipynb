{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31de8fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ratings = pd.read_table('ml-1m/ratings.dat',  sep = '::', engine = 'python', header = None, names= ['UserID', 'MovieID', 'Rating', 'Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50bc20e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 200042  200043  200044 ... 1000206 1000207 1000208] [     0      1      2 ... 200039 200040 200041]\n",
      "[      0       1       2 ... 1000206 1000207 1000208] [200042 200043 200044 ... 400081 400082 400083]\n",
      "[      0       1       2 ... 1000206 1000207 1000208] [400084 400085 400086 ... 600123 600124 600125]\n",
      "[      0       1       2 ... 1000206 1000207 1000208] [600126 600127 600128 ... 800165 800166 800167]\n",
      "[     0      1      2 ... 800165 800166 800167] [ 800168  800169  800170 ... 1000206 1000207 1000208]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5)\n",
    "for train, test in kf.split(ratings):\n",
    "    print(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef713038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global rmse:  1.117236564425969\n",
      "global mae:  0.9339855110655619\n",
      "user rmse:  1.1172260232723568\n",
      "user mae:  0.9339513695616997\n",
      "item rmse:  0.9800497988312646\n",
      "item mae:  0.9800497988312646\n"
     ]
    }
   ],
   "source": [
    "rmseglobalavg = []\n",
    "maeglobalavg = []\n",
    "rmseuseravg = []\n",
    "maeuseravg = []\n",
    "rmseitemavg = []\n",
    "maeitemavg = []\n",
    "\n",
    "for trainid, testid in kf.split(ratings):\n",
    "    \n",
    "    X_train = ratings[['UserID','MovieID']].iloc[trainid]\n",
    "    X_test = ratings[['UserID','MovieID']].iloc[testid]\n",
    "    y_train = ratings['Rating'].iloc[trainid]\n",
    "    y_test = ratings['Rating'].iloc[testid]\n",
    "    \n",
    "    # define averages\n",
    "    global_avg = y_train.mean()\n",
    "    user_avg = ratings[['UserID','Rating']].iloc[trainid].groupby(['UserID']).mean()\n",
    "    item_avg = ratings[['MovieID','Rating']].iloc[trainid].groupby(['MovieID']).mean()\n",
    " \n",
    "    # create lists to put results in\n",
    "    global_avg_pred = []\n",
    "    user_avg_pred = []\n",
    "    item_avg_pred = []\n",
    "    \n",
    "    # loop over test set\n",
    "    for x in testid:\n",
    "       \n",
    "        # predict using global average\n",
    "        global_avg_pred.append(global_avg)\n",
    "    \n",
    "        # predict using user average\n",
    "        if ratings['UserID'][x] in user_avg.index.tolist():\n",
    "            user_rating = user_avg.loc[ratings['UserID'][x]]\n",
    "            user_avg_pred.append(user_rating[0])\n",
    "        else: user_avg_pred.append(global_avg)\n",
    "        \n",
    "        # predict using item average\n",
    "        if ratings['MovieID'][x] in item_avg.index.tolist():\n",
    "            item_rating = item_avg.loc[ratings['MovieID'][x]]\n",
    "            item_avg_pred.append(item_rating[0])\n",
    "        else: item_avg_pred.append(global_avg)\n",
    "\n",
    "    # append results to lists\n",
    "    rmseglobalavg.append(math.sqrt(mean_squared_error(y_test, global_avg_pred)))\n",
    "    maeglobalavg.append(mean_absolute_error(y_test, global_avg_pred))\n",
    "    \n",
    "    rmseuseravg.append(math.sqrt(mean_squared_error(y_test,user_avg_pred)))\n",
    "    maeuseravg.append(mean_absolute_error(y_test, user_avg_pred))\n",
    "    \n",
    "    rmseitemavg.append(math.sqrt(mean_squared_error(y_test, item_avg_pred)))\n",
    "    maeitemavg.append(mean_absolute_error(y_test, item_avg_pred))\n",
    "\n",
    "# print averages of lists\n",
    "print('global rmse: ', sum(rmseglobalavg)/len(rmseglobalavg))\n",
    "print('global mae: ', sum(maeglobalavg)/len(maeglobalavg))\n",
    "print('user rmse: ', sum(rmseuseravg)/len(rmseuseravg))\n",
    "print('user mae: ', sum(maeuseravg)/len(maeuseravg))\n",
    "print('item rmse: ', sum(rmseitemavg)/len(rmseitemavg))\n",
    "print('item mae: ', sum(rmseitemavg)/len(maeitemavg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c88097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 rmse:  1.9266180062806786\n",
      "model 1 mae:  1.6152489879455783\n",
      "model 2 rmse:  1.1149420397630698\n",
      "model 2 mae:  0.930941138313008\n"
     ]
    }
   ],
   "source": [
    "# lists to put results in\n",
    "model1rmseavg = []\n",
    "model2rmseavg = []\n",
    "model1maeavg = []\n",
    "model2maeavg = []\n",
    "\n",
    "for trainid, testid in kf.split(ratings):\n",
    "    \n",
    "    X_train = ratings[['UserID','MovieID']].iloc[trainid]\n",
    "    X_test = ratings[['UserID','MovieID']].iloc[testid]\n",
    "    y_train = ratings['Rating'].iloc[trainid]\n",
    "    y_test = ratings['Rating'].iloc[testid]\n",
    "    \n",
    "    # predict using alpha*user + beta*item\n",
    "    model1 = LinearRegression(fit_intercept = False)\n",
    "    model1.fit(X_train, y_train)\n",
    "    pred1 = model1.predict(X_test)\n",
    "    \n",
    "    # predict using alpha*user + beta*item + gamma\n",
    "    model2 = LinearRegression()\n",
    "    model2.fit(X_train, y_train)\n",
    "    pred2 = model2.predict(X_test)\n",
    "    \n",
    "    # compute rmse and mae\n",
    "    rmse1 = math.sqrt(mean_squared_error(y_test, pred1))\n",
    "    mae1 = mean_absolute_error(y_test, pred1)\n",
    "    rmse2 = math.sqrt(mean_squared_error(y_test, pred2))\n",
    "    mae2 = mean_absolute_error(y_test, pred2)\n",
    "    \n",
    "    # add results to list\n",
    "    model1rmseavg.append(rmse1)\n",
    "    model2rmseavg.append(rmse2)\n",
    "    model1maeavg.append(mae1)\n",
    "    model2maeavg.append(mae2)\n",
    "    \n",
    "# print averages of lists\n",
    "print('model 1 rmse: ', sum(model1rmseavg)/len(model1rmseavg))\n",
    "print('model 1 mae: ', sum(model1maeavg)/len(model1maeavg))\n",
    "print('model 2 rmse: ', sum(model2rmseavg)/len(model2rmseavg))\n",
    "print('model 2 mae: ', sum(model2maeavg)/len(model2maeavg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af4632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
